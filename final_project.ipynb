{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8IbKK0VWYk3",
    "outputId": "d9e19ef2-7c29-42a1-acad-1d0c8136de45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sherryliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sherryliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sherryliu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sherryliu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8errENYHXtuE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tinder_google_play_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5L_7pmavYljj",
    "outputId": "e43047c6-12f2-4053-84e7-2c7e124d1b1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535406, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i0XOGdwYVrv",
    "outputId": "32b41961-d7ae-4977-cbce-b1fd1f59e2c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534062, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['content'],inplace=True)\n",
    "df.drop(columns=['reviewId', 'userImage'],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WxX8Uw_vYpuf"
   },
   "outputs": [],
   "source": [
    "df.sort_values('at', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-B_9MfgSY2Ja",
    "outputId": "c03853fc-c17b-4552-9838-866a0b15fd30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Daniel Rothermel</td>\n",
       "      <td>✓✓✓✓</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.23.0</td>\n",
       "      <td>2020-09-17 00:35:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Guero Guero</td>\n",
       "      <td>Mature grown with experience</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-17 00:06:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Alexander Waalen</td>\n",
       "      <td>I changed my phone # and forgot to cancel my s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-16 23:49:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>Ethan Shadows</td>\n",
       "      <td>My account was banned for reasons unbeknownst ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.23.0</td>\n",
       "      <td>2020-09-16 23:44:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>Stacey K</td>\n",
       "      <td>Not fun and have to pay for everything.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-16 23:32:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                userName                                            content  \\\n",
       "99997   Daniel Rothermel                                               ✓✓✓✓   \n",
       "99998        Guero Guero                       Mature grown with experience   \n",
       "99999   Alexander Waalen  I changed my phone # and forgot to cancel my s...   \n",
       "100000     Ethan Shadows  My account was banned for reasons unbeknownst ...   \n",
       "100001          Stacey K            Not fun and have to pay for everything.   \n",
       "\n",
       "        score  thumbsUpCount reviewCreatedVersion                   at  \\\n",
       "99997       5              0              11.23.0  2020-09-17 00:35:01   \n",
       "99998       5              0                  NaN  2020-09-17 00:06:21   \n",
       "99999       1              0                  NaN  2020-09-16 23:49:52   \n",
       "100000      1              1              11.23.0  2020-09-16 23:44:10   \n",
       "100001      1              0                  NaN  2020-09-16 23:32:37   \n",
       "\n",
       "       replyContent repliedAt  \n",
       "99997           NaN       NaN  \n",
       "99998           NaN       NaN  \n",
       "99999           NaN       NaN  \n",
       "100000          NaN       NaN  \n",
       "100001          NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(100000)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PslvBBtYZmit",
    "outputId": "4aaa4409-4935-4d1f-c43f-63498f2c9cb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userName                0.00003\n",
       "content                 0.00000\n",
       "score                   0.00000\n",
       "thumbsUpCount           0.00000\n",
       "reviewCreatedVersion    0.26611\n",
       "at                      0.00000\n",
       "replyContent            0.99574\n",
       "repliedAt               0.99574\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Mh96SxD0aC7e"
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words(\"english\")\n",
    "\n",
    "def get_vec(words, stop=stopword_list):\n",
    "    '''Revise the function by changing stop_words and adding token_pattern'''\n",
    "    vectorizer = CountVectorizer(stop_words=stop, lowercase=True, min_df=0.001, token_pattern=r'[a-z\\_\\-]{3,}', binary=True)\n",
    "    X = vectorizer.fit_transform(words) \n",
    "    X = X.toarray()\n",
    "    print(X.shape)\n",
    "    feature = vectorizer.get_feature_names()\n",
    "    corpus_df = pd.DataFrame(X, columns=feature)\n",
    "    return corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EpleobEJaTYm"
   },
   "outputs": [],
   "source": [
    "review = df['content'].tolist()\n",
    "review = [line.lower() for line in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RbiDhEJaWx0",
    "outputId": "5a1d036f-7fd5-4e38-de70-1a3e47156a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1050)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "app             31111\n",
       "tinder          11476\n",
       "banned          10966\n",
       "good            10184\n",
       "people           9783\n",
       "just             9090\n",
       "account          8509\n",
       "don              7392\n",
       "like             7219\n",
       "money            6971\n",
       "time             6434\n",
       "reason           6328\n",
       "got              6099\n",
       "pay              5715\n",
       "matches          5525\n",
       "fake             4930\n",
       "use              4810\n",
       "match            4712\n",
       "profiles         4248\n",
       "profile          4069\n",
       "nice             4032\n",
       "great            3828\n",
       "likes            3741\n",
       "dating           3675\n",
       "waste            3501\n",
       "new              3398\n",
       "gold             3296\n",
       "want             3290\n",
       "bad              2988\n",
       "worst            2951\n",
       "way              2934\n",
       "subscription     2860\n",
       "make             2811\n",
       "know             2682\n",
       "really           2671\n",
       "doesn            2585\n",
       "paid             2546\n",
       "used             2492\n",
       "getting          2450\n",
       "using            2395\n",
       "free             2340\n",
       "love             2293\n",
       "better           2265\n",
       "didn             2194\n",
       "service          2179\n",
       "work             2135\n",
       "won              2123\n",
       "experience       2084\n",
       "did              2013\n",
       "best             1998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = get_vec(review, 'english')\n",
    "corpus_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3qohf-kzabeh"
   },
   "outputs": [],
   "source": [
    "# https://tinder.com/feature/subscription-tiers\n",
    "def word_replace_pre_lem(line):\n",
    "    '''Before lemmitization, do the regex cleaning for features in Tinder'''\n",
    "    line = re.sub(r'\\bwho likes? you\\b', '_who_like_you_', line)\n",
    "    line = re.sub(r'\\bsuper likes?\\b', '_super_like_', line)\n",
    "    line = re.sub(r'\\blike(s|d)?\\b', '_likes_', line)\n",
    "    line = re.sub(r'\\bmatch(es|ed)?\\b', '_matches_', line)\n",
    "    line = re.sub(r'\\brewind(s)?\\b', '_rewind_', line)\n",
    "    line = re.sub(r'\\bpassport\\b', '_passport_', line)\n",
    "    line = re.sub(r'\\bmessages?\\b', '_message_', line)\n",
    "    line = re.sub(r'\\bmeets?\\b', '_meet_', line)\n",
    "    line = re.sub(r'\\bswipe(s| left| right)?\\b', '_swipe_', line)\n",
    "    line = re.sub(r'\\btop picks?\\b', '_top_pick_', line)\n",
    "    line = re.sub(r'\\b(tinder )?gold\\b', '_tinder_gold_', line)\n",
    "    line = re.sub(r'\\b(tinder )?plus\\b', '_tinder_plus_', line)\n",
    "    line = re.sub(r'\\b(tinder )?platinum\\b', '_tinder_platinum_', line)\n",
    "    line = re.sub(r'\\bpremium( features?)?\\b', '_premium_', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0OxnFpaFeiVd"
   },
   "outputs": [],
   "source": [
    "review_pre_lem = [word_replace_pre_lem(line) for line in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dKxCqGKhiDD",
    "outputId": "1a0cd0c4-887b-471c-9088-37b7d0d9539f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1046)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "app              31111\n",
       "banned           10966\n",
       "good             10184\n",
       "tinder           10176\n",
       "_matches_        10060\n",
       "people            9783\n",
       "_likes_           9571\n",
       "just              9090\n",
       "account           8509\n",
       "don               7392\n",
       "money             6971\n",
       "time              6434\n",
       "reason            6328\n",
       "got               6099\n",
       "pay               5715\n",
       "fake              4930\n",
       "use               4810\n",
       "profiles          4248\n",
       "profile           4069\n",
       "nice              4032\n",
       "great             3828\n",
       "dating            3675\n",
       "waste             3501\n",
       "_message_         3479\n",
       "new               3398\n",
       "_tinder_gold_     3296\n",
       "want              3290\n",
       "bad               2988\n",
       "worst             2951\n",
       "way               2934\n",
       "subscription      2860\n",
       "make              2811\n",
       "know              2682\n",
       "really            2671\n",
       "doesn             2585\n",
       "paid              2546\n",
       "used              2492\n",
       "getting           2450\n",
       "using             2395\n",
       "free              2340\n",
       "love              2293\n",
       "better            2265\n",
       "didn              2194\n",
       "service           2179\n",
       "work              2135\n",
       "won               2123\n",
       "experience        2084\n",
       "_swipe_           2032\n",
       "did               2013\n",
       "best              1998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = get_vec(review_pre_lem, 'english')\n",
    "corpus_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KR80fiLai3Io"
   },
   "outputs": [],
   "source": [
    "## Reference: https://gist.github.com/gaurav5430/9fce93759eb2f6b1697883c3782f30de#file-nltk-lemmatize-sentences-py\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def lem(sentence):\n",
    "    '''Intake a list of review, lemmatize them and return a new list'''\n",
    "    result_lem = []\n",
    "    for s in tqdm(sentence):\n",
    "        s_lem = lemmatize_sentence(s)\n",
    "        result_lem.append(s_lem)\n",
    "    return result_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(words, stop=stopword_list):\n",
    "    '''Revise the function by changing stop_words and adding token_pattern'''\n",
    "    vectorizer = CountVectorizer(stop_words=stop, lowercase=True, min_df=0.001, token_pattern=r'[a-z\\_\\-]{3,}', binary=True)\n",
    "    X = vectorizer.fit_transform(words) \n",
    "    X = X.toarray()\n",
    "    print(X.shape)\n",
    "    feature = vectorizer.get_feature_names()\n",
    "    corpus_df = pd.DataFrame(X, columns=feature)\n",
    "    return corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBcB_Wu_jD2S",
    "outputId": "12eec17e-14d3-47b5-cdd5-e559fc7b598c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [01:17<00:00, 1287.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 860)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "app              31112\n",
       "ban              12267\n",
       "good             11529\n",
       "tinder           10220\n",
       "_matches_        10060\n",
       "account           9971\n",
       "people            9887\n",
       "_likes_           9571\n",
       "pay               9129\n",
       "just              9090\n",
       "use               9054\n",
       "profile           7785\n",
       "time              7765\n",
       "money             6974\n",
       "reason            6631\n",
       "bad               6053\n",
       "make              5420\n",
       "fake              5178\n",
       "try               5041\n",
       "work              4534\n",
       "say               4161\n",
       "want              4052\n",
       "nice              4038\n",
       "waste             3967\n",
       "great             3861\n",
       "date              3609\n",
       "_message_         3479\n",
       "new               3439\n",
       "_tinder_gold_     3296\n",
       "day               3188\n",
       "subscription      3068\n",
       "way               3065\n",
       "know              3037\n",
       "month             2774\n",
       "year              2703\n",
       "really            2671\n",
       "need              2665\n",
       "service           2577\n",
       "look              2504\n",
       "love              2479\n",
       "delete            2471\n",
       "free              2342\n",
       "experience        2292\n",
       "send              2216\n",
       "let               2211\n",
       "tell              2175\n",
       "lot               2163\n",
       "fix               2047\n",
       "ask               2044\n",
       "_swipe_           2032\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lem = lem(review_pre_lem)\n",
    "corpus_df = get_vec(review_lem, 'english')\n",
    "corpus_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 964)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get              16019\n",
       "ban              12267\n",
       "good             11529\n",
       "tinder           10220\n",
       "_matches_        10060\n",
       "account           9971\n",
       "_likes_           9571\n",
       "pay               9129\n",
       "use               9054\n",
       "even              8058\n",
       "profile           7785\n",
       "time              7765\n",
       "money             6974\n",
       "reason            6631\n",
       "bad               6053\n",
       "make              5420\n",
       "fake              5178\n",
       "see               5161\n",
       "try               5041\n",
       "one               5008\n",
       "work              4534\n",
       "say               4161\n",
       "give              4120\n",
       "want              4052\n",
       "nice              4038\n",
       "waste             3967\n",
       "great             3861\n",
       "find              3743\n",
       "date              3609\n",
       "show              3601\n",
       "_message_         3479\n",
       "new               3439\n",
       "keep              3397\n",
       "never             3393\n",
       "_tinder_gold_     3296\n",
       "still             3276\n",
       "many              3264\n",
       "would             3258\n",
       "day               3188\n",
       "nothing           3154\n",
       "subscription      3068\n",
       "way               3065\n",
       "know              3037\n",
       "without           2916\n",
       "someone           2781\n",
       "month             2774\n",
       "back              2715\n",
       "year              2703\n",
       "really            2671\n",
       "need              2665\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = get_vec(review_lem, stopword_list)\n",
    "corpus_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "leF1jKbQlFOL"
   },
   "outputs": [],
   "source": [
    "def word_replace_post_lem(line):\n",
    "    '''After lemmitization, do the regex cleaning for known product issue'''\n",
    "    line = re.sub(r'\\b(ban|block|close|suspend)\\b', '_ban_', line)\n",
    "    line = re.sub(r'\\b(bug|crash)\\b', '_bug_', line)\n",
    "    line = re.sub(r'\\blog(-?in)?\\b', '_login_', line)\n",
    "    line = re.sub(r'\\b(fake( account| profile)?|bot|spam)\\b', '_fake_account_', line)\n",
    "    line = re.sub(r'\\b(scam|cheat)\\b', '_scam_', line)\n",
    "    line = re.sub(r'\\b(subscribe|subscription|membership)\\b', '_subscription_', line)\n",
    "    line = re.sub(r'\\b(charge|paywall|payment|in-app-purchase)\\b', '_payment_', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYc3SCLupjIZ",
    "outputId": "fd26e1c1-8758-44a3-b829-444062923f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 953)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get               16019\n",
       "_ban_             13797\n",
       "good              11529\n",
       "tinder            10220\n",
       "_matches_         10060\n",
       "_likes_            9571\n",
       "account            9245\n",
       "pay                9129\n",
       "use                9054\n",
       "even               8058\n",
       "time               7765\n",
       "_fake_account_     7026\n",
       "money              6974\n",
       "reason             6631\n",
       "profile            6208\n",
       "bad                6053\n",
       "make               5420\n",
       "see                5161\n",
       "try                5041\n",
       "one                5008\n",
       "work               4534\n",
       "_subscription_     4441\n",
       "say                4161\n",
       "give               4120\n",
       "want               4052\n",
       "nice               4038\n",
       "waste              3967\n",
       "great              3861\n",
       "find               3743\n",
       "date               3609\n",
       "show               3601\n",
       "_message_          3479\n",
       "new                3439\n",
       "keep               3397\n",
       "never              3393\n",
       "_tinder_gold_      3296\n",
       "still              3276\n",
       "many               3264\n",
       "would              3258\n",
       "day                3188\n",
       "nothing            3154\n",
       "way                3065\n",
       "know               3037\n",
       "without            2916\n",
       "someone            2781\n",
       "month              2774\n",
       "back               2715\n",
       "year               2703\n",
       "really             2671\n",
       "need               2665\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_final = [word_replace_post_lem(review) for review in review_lem]\n",
    "corpus_df = get_vec(review_final, stopword_list)\n",
    "corpus_df.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "zWgIGtRdquiX"
   },
   "outputs": [],
   "source": [
    "df['review_final'] = review_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_good = df[df['score'] >= 4]['review_final']\n",
    "review_bad = df[df['score'] < 4]['review_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.append('app')\n",
    "\n",
    "def get_tfidf_vec(review):\n",
    "    '''Intake a list of review and return tf-idf report'''\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2,2),\n",
    "                             token_pattern=r'\\b[a-zA-Z\\_]{3,}\\b',\n",
    "                             max_df=0.4, stop_words=stopword_list, max_features=1000, binary=True)\n",
    "    X = vectorizer.fit_transform(review)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "    tf_idf_sum = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf_sum, columns=[\"score\"])\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "    nmf = NMF(n_components=4)\n",
    "    W = nmf.fit_transform(X)\n",
    "    H = nmf.components_\n",
    "    tf_idf_topic = pd.DataFrame(X.toarray(), columns=terms)\n",
    "    def get_top_tf_idf_tokens_for_topic(H: np.array, feature_names: List[str], num_top_tokens: int = 5):\n",
    "        for topic, vector in enumerate(H):\n",
    "            print(f\"TOPIC {topic}\\n\")\n",
    "            total = vector.sum()\n",
    "            top_scores = vector.argsort()[::-1][:num_top_tokens]\n",
    "            token_names = list(map(lambda idx: feature_names[idx], top_scores))\n",
    "            strengths = list(map(lambda idx: vector[idx] / total, top_scores))\n",
    "\n",
    "            for strength, token_name in zip(strengths, token_names):\n",
    "                print(f\"\\b{token_name} ({round(strength * 100, 1)}%)\\n\")\n",
    "            print(f\"=\" * 50)\n",
    "    get_top_tf_idf_tokens_for_topic(H, tf_idf_topic.columns.tolist(), 5)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherryliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\beasy use (56.4%)\n",
      "\n",
      "\bgood easy (3.4%)\n",
      "\n",
      "\bnice easy (3.0%)\n",
      "\n",
      "\bgreat easy (2.5%)\n",
      "\n",
      "\bfun easy (1.3%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bfar good (76.5%)\n",
      "\n",
      "\bgood still (0.8%)\n",
      "\n",
      "\bgood meet (0.8%)\n",
      "\n",
      "\bgood really (0.8%)\n",
      "\n",
      "\bgood experience (0.7%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\bnew people (18.7%)\n",
      "\n",
      "\b_meet_ new (15.4%)\n",
      "\n",
      "\bmeet new (5.0%)\n",
      "\n",
      "\bway _meet_ (3.7%)\n",
      "\n",
      "\bnew friend (3.1%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 3\n",
      "\n",
      "\bbest ever (69.1%)\n",
      "\n",
      "\bbest dating (7.8%)\n",
      "\n",
      "\bone best (1.9%)\n",
      "\n",
      "\bever see (1.6%)\n",
      "\n",
      "\btinder best (1.0%)\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherryliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>easy use</th>\n",
       "      <td>264.285630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far good</th>\n",
       "      <td>162.690835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new people</th>\n",
       "      <td>152.227050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best dating</th>\n",
       "      <td>145.555727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best ever</th>\n",
       "      <td>128.800345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty good</th>\n",
       "      <td>121.157122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_meet_ new</th>\n",
       "      <td>119.238975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best date</th>\n",
       "      <td>115.329946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get _matches_</th>\n",
       "      <td>113.456256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_meet_ people</th>\n",
       "      <td>100.609507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great experience</th>\n",
       "      <td>91.913789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good experience</th>\n",
       "      <td>87.395168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new friend</th>\n",
       "      <td>86.897765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find love</th>\n",
       "      <td>86.635619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love life</th>\n",
       "      <td>84.110581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks tinder</th>\n",
       "      <td>80.822741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good one</th>\n",
       "      <td>76.307284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user friendly</th>\n",
       "      <td>75.169305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love tinder</th>\n",
       "      <td>74.875087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really good</th>\n",
       "      <td>68.952603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "easy use          264.285630\n",
       "far good          162.690835\n",
       "new people        152.227050\n",
       "best dating       145.555727\n",
       "best ever         128.800345\n",
       "pretty good       121.157122\n",
       "_meet_ new        119.238975\n",
       "best date         115.329946\n",
       "get _matches_     113.456256\n",
       "_meet_ people     100.609507\n",
       "great experience   91.913789\n",
       "good experience    87.395168\n",
       "new friend         86.897765\n",
       "find love          86.635619\n",
       "love life          84.110581\n",
       "thanks tinder      80.822741\n",
       "good one           76.307284\n",
       "user friendly      75.169305\n",
       "love tinder        74.875087\n",
       "really good        68.952603"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_good = get_tfidf_vec(review_good)\n",
    "score_good[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherryliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\b_ban_ reason (62.3%)\n",
      "\n",
      "\bgot _ban_ (7.5%)\n",
      "\n",
      "\breason even (1.3%)\n",
      "\n",
      "\breason give (1.0%)\n",
      "\n",
      "\breason explanation (0.8%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bwaste time (38.2%)\n",
      "\n",
      "\btime money (5.1%)\n",
      "\n",
      "\bget _matches_ (1.5%)\n",
      "\n",
      "\bdont waste (1.3%)\n",
      "\n",
      "\bcomplete waste (1.0%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\bget _ban_ (26.2%)\n",
      "\n",
      "\baccount get (5.5%)\n",
      "\n",
      "\b_ban_ without (1.5%)\n",
      "\n",
      "\b_ban_ nothing (1.1%)\n",
      "\n",
      "\bcustomer service (0.9%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 3\n",
      "\n",
      "\baccount _ban_ (21.7%)\n",
      "\n",
      "\b_ban_ account (2.8%)\n",
      "\n",
      "\b_ban_ without (2.3%)\n",
      "\n",
      "\bsay account (1.9%)\n",
      "\n",
      "\bwithout reason (1.5%)\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_ban_ reason</th>\n",
       "      <td>1504.349171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get _ban_</th>\n",
       "      <td>1244.846308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste time</th>\n",
       "      <td>1170.816817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account _ban_</th>\n",
       "      <td>841.360155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get _matches_</th>\n",
       "      <td>756.659753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ban_ account</th>\n",
       "      <td>586.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many _fake_account_</th>\n",
       "      <td>484.777878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete account</th>\n",
       "      <td>455.150144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer service</th>\n",
       "      <td>438.820651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste money</th>\n",
       "      <td>432.051418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone number</th>\n",
       "      <td>384.015904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got _ban_</th>\n",
       "      <td>375.094747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad ever</th>\n",
       "      <td>371.704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ban_ without</th>\n",
       "      <td>365.891059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account get</th>\n",
       "      <td>348.379218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad experience</th>\n",
       "      <td>307.834795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see _likes_</th>\n",
       "      <td>296.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mile away</th>\n",
       "      <td>281.559959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send _message_</th>\n",
       "      <td>281.336986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancel _subscription_</th>\n",
       "      <td>271.205368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             score\n",
       "_ban_ reason           1504.349171\n",
       "get _ban_              1244.846308\n",
       "waste time             1170.816817\n",
       "account _ban_           841.360155\n",
       "get _matches_           756.659753\n",
       "_ban_ account           586.002440\n",
       "many _fake_account_     484.777878\n",
       "delete account          455.150144\n",
       "customer service        438.820651\n",
       "waste money             432.051418\n",
       "phone number            384.015904\n",
       "got _ban_               375.094747\n",
       "bad ever                371.704887\n",
       "_ban_ without           365.891059\n",
       "account get             348.379218\n",
       "bad experience          307.834795\n",
       "see _likes_             296.265500\n",
       "mile away               281.559959\n",
       "send _message_          281.336986\n",
       "cancel _subscription_   271.205368"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_bad = get_tfidf_vec(review_bad)\n",
    "score_bad[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP final project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
